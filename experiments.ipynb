{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f799f77-2472-4645-b18f-df8b4c1e8e49",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd59c39-1a6c-470f-91ad-cbcd82d7e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import custom implementations\n",
    "#import SVDRecommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23109be-da0f-4fc1-98b6-358ff4d6bef6",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebaf07-9109-4c39-b100-54890017280b",
   "metadata": {},
   "source": [
    "# Running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c571fb5e-963d-4b86-89a9-bad42462675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def one_simulation(X_train, X_test, y_train, y_test, recommender, metrics):\n",
    "    \"\"\"\n",
    "    Run one simulation of training and testing a recommender.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pandas.DataFrame\n",
    "        Training features data.\n",
    "    X_test : pandas.DataFrame\n",
    "        Testing features data.\n",
    "    y_train : pandas.Series\n",
    "        Training target data.\n",
    "    y_test : pandas.Series\n",
    "        Testing target data.\n",
    "    recommender : object\n",
    "        Recommender object to fit and predict with.\n",
    "    metrics : dict\n",
    "        Dictionary of metric names and metric functions.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of metric results for the recommender, containing metric names and metric values.\n",
    "    \"\"\"\n",
    "    # Fit recommender on training set\n",
    "    recommender.fit(X_train, y_train)\n",
    "\n",
    "    # Get predictions on testing set\n",
    "    y_pred = recommender.predict(X_test)\n",
    "\n",
    "    # Calculate metrics and save to dictionary\n",
    "    metrics_results = {metric_name : metric(y_test, y_pred) for metric_name, metric in metrics.items()}\n",
    "\n",
    "    # Return metrics results dictionary\n",
    "    return metrics_results\n",
    "    \n",
    "def run_simulations(n_repetitions, recommenders, X, y, metrics):\n",
    "    \"\"\"\n",
    "    Run n_repetitions of simulations for each recommender in recommenders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_repetitions : int\n",
    "        Number of repetitions to run for each recommender.\n",
    "    recommenders : dict\n",
    "        Dictionary of recommender names and recommender objects.\n",
    "    X : pandas.DataFrame\n",
    "        Features data.\n",
    "    y : pandas.Series\n",
    "        Target data.\n",
    "    metrics : dict\n",
    "        Dictionary of metric names and metric functions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of results for each recommender, containing lists of metric values for each repetition.\n",
    "    \"\"\"\n",
    "    # Initialize variables to hold results\n",
    "    results = {recommender_name : {metric_name : [] for metric_name in metrics.keys()} for recommender_name in recommenders.keys()}\n",
    "    \n",
    "    # Iterate over n_repetitions, recommenders\n",
    "    for i in range(n_repetitions):\n",
    "        for recommender_name, recommender in recommenders.items():\n",
    "            # Randomly train test split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "            # Run one_simulation for each repetition X recommender combo\n",
    "            metrics_results = one_simulation(X_train, X_test, y_train, y_test, recommender, metrics)\n",
    "            # Save results\n",
    "            for metric_name, metric_result in metrics_results.items():\n",
    "                results[recommender_name][metric_name].append(metric_result)\n",
    "\n",
    "    # Return all results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c1288dc-d929-4220-9f0b-04f5782967ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVDRecommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Experiment parameters\u001b[39;00m\n\u001b[1;32m      2\u001b[0m n_repetitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      4\u001b[0m recommenders \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m'\u001b[39m : SVDRecommender()\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m : rmse\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Running experiments\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVDRecommender' is not defined"
     ]
    }
   ],
   "source": [
    "# Experiment parameters\n",
    "n_repetitions = 5\n",
    "\n",
    "recommenders = {\n",
    "    'svd' : SVDRecommender()\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    'rmse' : rmse\n",
    "}\n",
    "\n",
    "# Running experiments\n",
    "results = run_simulations(n_repetitions=n_repetitions, recommenders=recommenders, X=X, y=y, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85284d-b86a-4e3f-86fd-a0aaee703e6e",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc9c23-bf79-4781-b9ae-2dff784aeea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
